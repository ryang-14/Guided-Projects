{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guided Project: Popular Data Science Questions\n",
    "The goal of this project is to find content that is interesting for designing a data science education service. We'll be looking through the [Data Science Stack Exhange](https://datascience.stackexchange.com/) website for popular subjects that interests people. With the subjects we find, we can potentially include them when we create content for our service."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stack Exchange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__What kind of questions are welcomed on this site?__\n",
    "\n",
    "In the help center of the DSSE website, we can read that we should:\n",
    "\n",
    "- Avoid asking subjective questions\n",
    "- Ask practical questions about Data Science.\n",
    "- Ask specific questions and reasonably scoped questions.\n",
    "- Make questions relevant to others.\n",
    "\n",
    "These types of questions will allow for us to sufficiently see what kind of questions people are wanting to learn about, and will be useful for our goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "__What, other than questions, does the site's home subdivide into?__\n",
    "\n",
    "Besides the [home](https://datascience.stackexchange.com/), we can see that DSSE is divided into four other sections which includes:\n",
    "- [Questions](https://datascience.stackexchange.com/questions)\n",
    "\n",
    "- [Tags](https://datascience.stackexchange.com/tags) to sub-topics that includes:\n",
    "    - Machine learning\n",
    "    - Python\n",
    "    - Neural network\n",
    "    - Deep learning\n",
    "    - Classification\n",
    "    - Keras\n",
    "    - And many more...\n",
    "\n",
    "- [Users](https://datascience.stackexchange.com/users)\n",
    "- [Unanswered](https://datascience.stackexchange.com/unanswered)\n",
    "\n",
    "The most useful section may be the `Tags` section, while the least useful sections are the `Unanswered` and `Users` sections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ What information is available in each post?__\n",
    "\n",
    "Looking at the most upvoted topics in DSSE, I can see that a `User` can post an in-depth question asking for guidance or explanations about a problem they wish to know more about, more explicitly, a problem in which they are working on.\n",
    "\n",
    "Each post includes:\n",
    "- Post Title\n",
    "- Post Author\n",
    "- Question(s)\n",
    "- Post Score\n",
    "- Other User's responses\n",
    "- Date of the post\n",
    "- The last active time on post\n",
    "- How much the post has been viewed\n",
    "- How many times the post has been Favorited"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Stack Exchange Data Explorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to find data we need about DSSE, we will be using the [Stack Exhange Data Explorer](https://data.stackexchange.com/datascience/query/new). The data explorer is a website that allows you to query into the DSSE databse using [Transact-SQL](https://en.wikipedia.org/wiki/Transact-SQL). While exploring and experimenting with the Data Explorer, I believe the most useful table to query is the `Posts` table.\n",
    "\n",
    "The `Posts` Table includes:\n",
    "- Id\n",
    "- PostTypeId \n",
    "- Score\n",
    "- ViewCount\n",
    "- Tags\n",
    "- CreationDate\n",
    "- AnswerCount\n",
    "- FavoriteCount\n",
    "\n",
    "These are the columns I believe will be the most useful in achieving the goal. `PostTypeId` can help us determine Between a question or an answer. `Score`, `ViewCount`, `Title`, `AnswerCount`, `FavoriteCount` will give us a popularity gauge. `Tags` will show us sub-topics about that are ppopular within a post. `CreationDate` will help us determine the time frame in which these questions will ask so we will be able to see what are popular questions as of late."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the following code below in Data Explorer, will provide the data we need to accomplish our goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`SELECT \n",
    "  Id,\n",
    "  CreationDate,\n",
    "  Score,\n",
    "  ViewCount,\n",
    "  Tags,\n",
    "  AnswerCount,\n",
    "  FavoriteCount\n",
    "FROM posts\n",
    "WHERE PostTypeId = 2 AND YEAR(CreationDate) = 2019;`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can save the results of this query from the Data Explorer as a .csv file so we can explore the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in libraries to be used\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "questions = pd.read_csv(\"2019_questions.csv\", parse_dates=[\"CreationDate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8839 entries, 0 to 8838\n",
      "Data columns (total 7 columns):\n",
      "Id               8839 non-null int64\n",
      "CreationDate     8839 non-null datetime64[ns]\n",
      "Score            8839 non-null int64\n",
      "ViewCount        8839 non-null int64\n",
      "Tags             8839 non-null object\n",
      "AnswerCount      8839 non-null int64\n",
      "FavoriteCount    1407 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(1), int64(4), object(1)\n",
      "memory usage: 483.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Explore/Observe the Dataset\n",
    "questions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There is 72% of missing data from the `FavoriteCount` column, which also seems to be the only column with missing data. A missing valuein this may indicate that the question is not present in any person's favorite list. We can replace the missing values with a zero, and change the column type to `int` since it no longer needs to be type `float`.\n",
    "\n",
    "The `Tags` column as data type object, let's determine what what `types` the `objects` in `questions[\"Tag\"]` are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([<class 'str'>], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions[\"Tags\"].apply(lambda value: type(value)).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Tags` column are all type string. Each post in Stack exchange are limited to a maximum of five tags. In our dataframe, we could separate our `Tags` column into five columns (one for each tag), however this method doesn't seem useful so we can keep it as a list of strings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, Stack Exchange's Data explorer provided clean data. Other than these two columns, the rest of the data seems to be of adequate data types and no other data are missing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8839 entries, 0 to 8838\n",
      "Data columns (total 7 columns):\n",
      "Id               8839 non-null int64\n",
      "CreationDate     8839 non-null datetime64[ns]\n",
      "Score            8839 non-null int64\n",
      "ViewCount        8839 non-null int64\n",
      "Tags             8839 non-null object\n",
      "AnswerCount      8839 non-null int64\n",
      "FavoriteCount    8839 non-null int64\n",
      "dtypes: datetime64[ns](1), int64(5), object(1)\n",
      "memory usage: 483.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Fill in the `FavoriteCount` column with zeros\n",
    "questions.fillna(value ={\"FavoriteCount\":0}, inplace=True)\n",
    "\n",
    "# Change the datatype of the `FavoriteCount` column\n",
    "questions[\"FavoriteCount\"] = questions[\"FavoriteCount\"].astype(int)\n",
    "\n",
    "# Print information on the dataset\n",
    "questions.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `Tags` column looks like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      <machine-learning><data-mining>\n",
       "1    <machine-learning><regression><linear-regressi...\n",
       "2         <python><time-series><forecast><forecasting>\n",
       "Name: Tags, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions.iloc[0:3, 4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of `Tags` contain `<` and `>` as separators. We can transform this list of string to look more suitable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# replace separators in the Tags columns\n",
    "questions[\"Tags\"] = questions[\"Tags\"].str.replace(\"^<|>$\",\"\").str.split(\"><\")\n",
    "questions.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Most Used and Most Viewed Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will look at how man times a tag has been used and viewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create empty dictionary to keep track of count\n",
    "tag_count = dict()\n",
    "\n",
    "# Loop to create count for tag_count dict\n",
    "for tags in questions[\"Tags\"]:\n",
    "    for tag in tags:\n",
    "        if tag in tag_count:\n",
    "            tag_count[tag] += 1\n",
    "        else:\n",
    "            tag_count[tag] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Change aesthetics of tag_count\n",
    "tag_count = pd.DataFrame.from_dict(tag_count, orient=\"index\")\n",
    "tag_count.rename(columns={0:\"Count\"}, inplace=True)\n",
    "tag_count.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sort the Count by value\n",
    "most_used = tag_count.sort_values(by=\"Count\").tail(20)\n",
    "most_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualize the tags counted\n",
    "most_used.plot(kind=\"barh\", figsize=(14,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing a view of 20 tags is not necessary and some tags may not be as much use. This should be enough tags to accomplish our goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "For the next part where we want to see the times each tag is viewed, we can use Python's builtin `enumerate()` function. Its utility is well understood by seeing it action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "some_iteration = \"Iterate\"\n",
    "\n",
    "for i, c in enumerate(some_iteration):\n",
    "    print(i, c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `enumerate()` function prints the `element` and the `index` of each of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dictionary for tag view count\n",
    "tag_view_count = dict()\n",
    "\n",
    "# Loop through Tags and count the views\n",
    "for idx, tags in enumerate(questions[\"Tags\"]):\n",
    "    for tag in tags:\n",
    "        if tag in tag_view_count:\n",
    "            tag_view_count[tag] += questions[\"ViewCount\"].iloc[idx]\n",
    "        else:\n",
    "            tag_view_count[tag] = 1\n",
    "\n",
    "# Modify the aesthetic\n",
    "tag_view_count = pd.DataFrame.from_dict(tag_view_count, orient=\"index\")\n",
    "tag_view_count.rename(columns={0:\"ViewCount\"}, inplace=True)\n",
    "\n",
    "# Sort the data\n",
    "most_viewed = tag_view_count.sort_values(by=\"ViewCount\").tail(20)\n",
    "\n",
    "# Create plot of the data\n",
    "most_viewed.plot(kind=\"barh\", figsize=(14, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's view them side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows = 1, ncols=2)\n",
    "fig.set_size_inches((20,10))\n",
    "most_used.plot(kind=\"barh\", ax=axs[0], subplots=True)\n",
    "most_viewed.plot(kind=\"barh\", ax=axs[1], subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merging the two data of tags together\n",
    "in_used = pd.merge(most_used, most_viewed, how=\"left\", left_index=True, right_index=True)\n",
    "in_viewed = pd.merge(most_used, most_viewed, how=\"right\", left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(in_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(in_viewed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relations Between Tags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A way of trying to gauge how pairs of tags are related to each other, is to count how many times teach tag appears with another.\n",
    "\n",
    "We can first create a list of all the tags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List of all tags\n",
    "all_tags = list(tag_count.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# List of all the tags\n",
    "print(all_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now create a dataframe where each row will represent a tag, and each column will also represent a tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dataframe with index and columns are tags\n",
    "tag_associations = pd.DataFrame(index=all_tags, columns=all_tags)\n",
    "\n",
    "# Print out what the Dataframe looks like\n",
    "tag_associations.iloc[0:4,0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we fill this dataframe with zeroes and then, for each lists of tags in `questions[\"Tags\"]`, we will increment the intervening tags by one. The result will be a dataframe that for each pair of tags, it tells us how many times they were used together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tag_associations.fillna(0, inplace=True)\n",
    "\n",
    "for tags in questions[\"Tags\"]:\n",
    "    tag_associations.loc[tags, tags] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's focus our attention on the most used tags. We'll add some colors to make it easier to talk about the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "relations_most_used = tag_associations.loc[most_used.index, most_used.index]\n",
    "\n",
    "def style_cells(x):\n",
    "    helper_df = pd.DataFrame('', index=x.index, columns=x.columns)\n",
    "    helper_df.loc[\"time-series\", \"r\"] = \"background-color: yellow\"\n",
    "    helper_df.loc[\"r\", \"time-series\"] = \"background-color: yellow\"\n",
    "    for k in range(helper_df.shape[0]):\n",
    "        helper_df.iloc[k,k] = \"color: blue\"\n",
    "    \n",
    "    return helper_df\n",
    "\n",
    "relations_most_used.style.apply(style_cells, axis=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cells highlighted in yellow tell us that `time-series` was used together with `r` 22 times. The values in blue tell us how many times each of the tags was used. We saw earlier that `machine-learning` was used `2693` times and we confirm it in this dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is difficult to understand what is going on in this dataframe. We can try to create a heatmap as a visualization to simplify the complexity. But before we do it, let's get rid of the values in blue, otherwise the colors will be too skewed, and it will misrepresent the data in the visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the blue values to NaN\n",
    "for i in range(relations_most_used.shape[0]):\n",
    "    relations_most_used.iloc[i,i] = pd.np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a heatmap for the tags\n",
    "plt.figure(figsize=(12,8))\n",
    "sns.heatmap(relations_most_used, cmap=\"PuBu\", annot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most used tags also seem to have the strongest relationships, as given by the dark concentration in the bottom right corner. However, this could simply be because each of these tags is used a lot, and so end up being used together a lot without possibly even having any strong relation between each other.\n",
    "\n",
    "A more intuitive manifestation of this phenomenon is the following. A lot of people buy bread, a lot of people buy toilet paper, so they end up being purchased together a lot, but purchasing one of them doesn't increase the chances of purchasing the other.\n",
    "\n",
    "Another shortcoming of this attempt is that it only looks at relations between pairs of tags and not between multiple groups of tags. For example, it could be the case that when used together, dataset and scikit-learn have a \"strong\" relation to pandas, but each by itself doesn't."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enter Domain Knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing some research and digging deeper, we find that `keras`, `TensorFlow`, and `sci-kit learn` are libraries used in `Python` to employ `deep-learning` (which is a type of `neural network` and and extension of `machine learning`).\n",
    "\n",
    "If we wanted to create a course around these top tags, we could recommend a course in Python with a focus on machine learning that extends into deep learning for the usage of classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It is just a Fad?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
